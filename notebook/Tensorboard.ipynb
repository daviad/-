{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "TensorBoard可以将训练过程中的各种绘制数据展示出来，包括标量（scalars），图片（images），音频（Audio）,计算图（graph）,数据分布，直方图（histograms）和嵌入式向量。   \n",
    "使用TensorBoard展示数据，需要在执行Tensorflow就算图的过程中，将各种类型的数据汇总并记录到日志文件中。然后使用TensorBoard读取这些日志文件，解析数据并生产数据可视化的Web页面，让我们可以在浏览器中观察各种汇总数据。\n",
    "summary_op包括了summary.scalar、summary.histogram、summary.image等操作，这些操作输出的是各种summary protobuf，最后通过summary.writer写入到event文件中。\n",
    "Tensorflow API中包含系列生成summary数据的API接口，这些函数将汇总信息存放在protobuf中，以字符串形式表达。\n",
    "\n",
    "1. 对标量数据汇总和记录使用tf.summary.scalar，函数格式如下：   \n",
    " tf.summary.scalar(tags, values, collections=None, name=None)    \n",
    "  一般在画loss,accuary时会用到这个函数。\n",
    "\n",
    "2. 使用tf.summary.histogram直接记录变量var的直方图，输出带直方图的汇总的protobuf，函数格式如下：\n",
    " tf.summary.histogram(tag, values, collections=None, name=None）  \n",
    "\n",
    "3. 输出带图像的probuf，汇总数据的图像的的形式如下： ' tag /image/0', ' tag /image/1', etc.，如：input/image/0等  \n",
    " tf.summary.image(tag, tensor, max_images=3, collections=None, name=None)  \n",
    "\n",
    "4. 将上面几种类型的汇总再进行一次合并，具体合并哪些由inputs指定，格式如下：\n",
    " tf.summary.merge(inputs, collections=None, name=None)\n",
    "\n",
    "5. 合并默认图形中的所有汇总：\n",
    " tf.summaries.merge_all(key='summaries')  \n",
    "\n",
    "6. 将汇总的protobuf写入到event文件中去的相关的类： SummaryWriter是一个类，它可以调用以下成员函数来往event文件中添加相关的数据 addsummary(), add sessionlog(), add_event(), or add_graph()\n",
    " tf.summary.FileWriter  \n",
    " 这里注意，计算图形的信息通过add_graph写入到event文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "\n",
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "首先载入Tensorflow，并设置训练的最大步数为1000,学习率为0.001,dropout的保留比率为0.9。\n",
    "同时，设置MNIST数据下载地址data_dir和汇总数据的日志存放路径log_dir。\n",
    "这里的日志路径log_dir非常重要，会存放所有汇总数据供Tensorflow展示。\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "max_step = 1000\n",
    "learning_rate = 0.001\n",
    "dropout = 0.9\n",
    "data_dir = '/tmp/tensorflow/mnist/input_data'\n",
    "log_dir = 'tmp/tensorflow/mnist/logs/mnist_with_summaries'\n",
    "\n",
    "# 使用input_data.read_data_sets下载MNIST数据，并创建Tensorflow的默认Session\n",
    "mnist = input_data.read_data_sets(data_dir, one_hot=True)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\"\"\"\n",
    "为了在TensorBoard中展示节点名称，设计网络时会常使用tf.name_scope限制命名空间，\n",
    "在这个with下所有的节点都会自动命名为input/xxx这样的格式。\n",
    "定义输入x和y的placeholder，并将输入的一维数据变形为28×28的图片存储到另一个tensor，\n",
    "这样就可以使用tf.summary.image将图片数据汇总给TensorBoard展示了。\n",
    "\"\"\"\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name='x_input')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y_input')\n",
    "\n",
    "with tf.name_scope('input_reshape'):\n",
    "    image_shaped_input = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image('input', image_shaped_input, 10)\n",
    "\n",
    "# 定义神经网络模型参数的初始化方法，\n",
    "# 权重依然使用常用的truncated_normal进行初始化，偏置则赋值为0.1\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 定义对Variable变量的数据汇总函数\n",
    "\"\"\"\n",
    "计算出Variable的mean,stddev,max和min，\n",
    "对这些标量数据使用tf.summary.scalar进行记录和汇总。\n",
    "同时，使用tf.summary.histogram直接记录变量var的直方图。\n",
    "\"\"\"\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var-mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)\n",
    "\n",
    "# 设计一个MLP多层神经网络来训练数据，在每一层中都会对模型参数进行数据汇总。\n",
    "\"\"\"\n",
    "定一个创建一层神经网络并进行数据汇总的函数nn_layer。\n",
    "这个函数的输入参数有输入数据input_tensor,输入的维度input_dim,输出的维度output_dim和层名称layer_name，激活函数act则默认使用Relu。\n",
    "在函数内，显示初始化这层神经网络的权重和偏置，并使用前面定义的variable_summaries对variable进行数据汇总。\n",
    "然后对输入做矩阵乘法并加上偏置，再将未进行激活的结果使用tf.summary.histogram统计直方图。\n",
    "同时，在使用激活函数后，再使用tf.summary.histogram统计一次。\n",
    "\"\"\"\n",
    "def nn_layer(input_tensor, input_dim, output_dim, layer_name,act=tf.nn.relu):\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weight'):\n",
    "            weights = weight_variable([input_dim, output_dim])\n",
    "            variable_summaries(weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = bias_variable([output_dim])\n",
    "            variable_summaries(biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            preactivate = tf.matmul(input_tensor, weights) + biases\n",
    "            tf.summary.histogram('pre_activations', preactivate)\n",
    "        activations = act(preactivate, name='actvations')\n",
    "        tf.summary.histogram('activations', activations)\n",
    "        return activations\n",
    "\n",
    "\"\"\"\n",
    "使用刚定义好的nn_layer创建一层神经网络，输入维度是图片的尺寸（784=24×24），输出的维度是隐藏节点数500.\n",
    "再创建一个Droput层，并使用tf.summary.scalar记录keep_prob。然后再使用nn_layer定义神经网络的输出层，激活函数为全等映射，此层暂时不使用softmax,在后面会处理。\n",
    "\"\"\"\n",
    "hidden1 = nn_layer(x, 784, 500, 'layer1')\n",
    "\n",
    "with tf.name_scope('dropout'):\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    tf.summary.scalar('dropout_keep_probability', keep_prob)\n",
    "    dropped = tf.nn.dropout(hidden1, keep_prob)\n",
    "\n",
    "y1 = nn_layer(dropped, 500, 10, 'layer2', act=tf.identity)\n",
    "\n",
    "\"\"\"\n",
    "这里使用tf.nn.softmax_cross_entropy_with_logits()对前面输出层的结果进行softmax处理并计算交叉熵损失cross_entropy。\n",
    "计算平均损失，并使用tf.summary.saclar进行统计汇总。\n",
    "\"\"\"\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    diff = tf.nn.softmax_cross_entropy_with_logits(logits=y1, labels=y)\n",
    "    with tf.name_scope('total'):\n",
    "        cross_entropy = tf.reduce_mean(diff)\n",
    "tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "\"\"\"\n",
    "使用Adma优化器对损失进行优化，同时统计预测正确的样本数并计算正确率accuray，\n",
    "再使用tf.summary.scalar对accuracy进行统计汇总。\n",
    "\"\"\"\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y1, 1), tf.arg_max(y, 1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "\"\"\"\n",
    "由于之前定义了非常多的tf.summary的汇总操作，一一执行这些操作态麻烦，\n",
    "所以这里使用tf.summary.merger_all()直接获取所有汇总操作，以便后面执行。\n",
    "然后，定义两个tf.summary.FileWrite(文件记录器)在不同的子目录，分别用来存放训练和测试的日志数据。\n",
    "同时，将Session的计算图sess.graph加入训练过程的记录器，这样在TensorBoard的GRAPHS窗口中就能展示整个计算图的可视化效果。\n",
    "最后使用tf.global_variables_initializer().run()初始化全部变量。\n",
    "\"\"\"\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(log_dir + '/train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(log_dir + '/test')\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "\"\"\"\n",
    "定义feed_dict的损失函数。\n",
    "该函数先判断训练标记，如果训练标记为true,则从mnist.train中获取一个batch的样本，并设置dropout值;\n",
    "如果训练标记为False，则获取测试数据，并设置keep_prob为1,即等于没有dropout效果。\n",
    "\"\"\"\n",
    "def feed_dict(train):\n",
    "    if train:\n",
    "        xs, ys = mnist.train.next_batch(100)\n",
    "        k = dropout\n",
    "    else:\n",
    "        xs, ys = mnist.test.images, mnist.test.labels\n",
    "        k = 1.0\n",
    "    return {x: xs, y: ys, keep_prob: k}\n",
    "\n",
    "# 实际执行具体的训练，测试及日志记录的操作\n",
    "\"\"\"\n",
    "首先，使用tf.train.Saver()创建模型的保存器。\n",
    "然后，进入训练的循环中，每隔10步执行一次merged（数据汇总），accuracy（求测试集上的预测准确率）操作，\n",
    "并使应test_write.add_summary将汇总结果summary和循环步数i写入日志文件;\n",
    "同时每隔100步，使用tf.RunOption定义Tensorflow运行选项，其中设置trace_level为FULL——TRACE,\n",
    "并使用tf.RunMetadata()定义Tensorflow运行的元信息，\n",
    "这样可以记录训练是运算时间和内存占用等方面的信息.\n",
    "再执行merged数据汇总操作和train_step训练操作，将汇总summary和训练元信息run_metadata添加到train_writer.\n",
    "平时，则执行merged操作和train_step操作，并添加summary到trian_writer。\n",
    "所有训练全部结束后，关闭train_writer和test_writer。\n",
    "\"\"\"\n",
    "saver = tf.train.Saver()\n",
    "for i in range(max_step):\n",
    "    if i % 10 == 0:\n",
    "        summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(False))\n",
    "        test_writer.add_summary(summary, i)\n",
    "        print('Accuracy at step %s: %s' % (i, acc))\n",
    "    else:\n",
    "        if i % 100 == 99:\n",
    "            run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "            run_metadata = tf.RunMetadata()\n",
    "            summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(True),\n",
    "                                  options=run_options, run_metadata=run_metadata)\n",
    "            train_writer.add_run_metadata(run_metadata, 'step%03d' % i)\n",
    "            train_writer.add_summary(summary, i)\n",
    "            saver.save(sess, log_dir+\"/model.ckpt\", i)\n",
    "            print('Adding run metadata for', i)\n",
    "        else:\n",
    "            summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(True))\n",
    "            train_writer.add_summary(summary, i)\n",
    "train_writer.close()\n",
    "test_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
