{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    "with tf.name_scope('graph2') as scope:\n",
    "  matrix1 = tf.constant([[3., 3.]],name ='matrix1')  #1 row by 2 column\n",
    "  matrix2 = tf.constant([[2.],[2.]],name ='matrix2') # 2 row by 1 column\n",
    "  product = tf.matmul(matrix1, matrix2,name='product')   \n",
    "  sess = tf.Session()  \n",
    "  writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "  init = tf.global_variables_initializer() \n",
    "  print(sess.run(init))\n",
    "  print(sess.run(product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "线性拟合（一）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,weight:[-0.38632375],bias:[0.61955804]\n",
      "10,weight:[-0.08976102],bias:[0.30175227]\n",
      "20,weight:[0.09836163],bias:[0.20437412]\n",
      "30,weight:[0.19568475],bias:[0.15399675]\n",
      "40,weight:[0.24603371],bias:[0.12793459]\n",
      "50,weight:[0.27208117],bias:[0.11445163]\n",
      "60,weight:[0.28555652],bias:[0.10747639]\n",
      "70,weight:[0.29252785],bias:[0.10386781]\n",
      "80,weight:[0.29613438],bias:[0.10200097]\n",
      "90,weight:[0.29800016],bias:[0.10103518]\n",
      "100,weight:[0.2989654],bias:[0.10053555]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "## prepare the original data\n",
    "with tf.name_scope('data'):\n",
    "     x_data = np.random.rand(100).astype(np.float32)\n",
    "     y_data = 0.3*x_data+0.1\n",
    "##creat parameters\n",
    "with tf.name_scope('parameters'):\n",
    "     weight = tf.Variable(tf.random_uniform([1],-1.0,1.0))\n",
    "     bias = tf.Variable(tf.zeros([1]))\n",
    "##get y_prediction\n",
    "with tf.name_scope('y_prediction'):\n",
    "     y_prediction = weight*x_data+bias\n",
    "##compute the loss\n",
    "with tf.name_scope('loss'):\n",
    "     loss = tf.reduce_mean(tf.square(y_data-y_prediction))\n",
    "##creat optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "#creat train ,minimize the loss \n",
    "with tf.name_scope('train'):\n",
    "     train = optimizer.minimize(loss)\n",
    "#creat init\n",
    "with tf.name_scope('init'): \n",
    "     init = tf.global_variables_initializer()\n",
    "##creat a Session \n",
    "sess = tf.Session()\n",
    "##initialize\n",
    "writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "sess.run(init)\n",
    "## Loop\n",
    "for step  in  range(101):\n",
    "    sess.run(train)\n",
    "    if step %10==0 :\n",
    "        print(\"{s},weight:{w},bias:{b}\".format(s=step,w=sess.run(weight),b=sess.run(bias)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "## prepare the original data\n",
    "with tf.name_scope('data'):\n",
    "     x_data = np.random.rand(100).astype(np.float32)\n",
    "     y_data = 0.3*x_data+0.1\n",
    "##creat parameters\n",
    "with tf.name_scope('parameters'):\n",
    "     with tf.name_scope('weights'):\n",
    "           weight = tf.Variable(tf.random_uniform([1],-1.0,1.0))\n",
    "           tf.summary.histogram('weight',weight)\n",
    "     with tf.name_scope('biases'):\n",
    "           bias = tf.Variable(tf.zeros([1]))\n",
    "           tf.summary.histogram('bias',bias)\n",
    "##get y_prediction\n",
    "with tf.name_scope('y_prediction'):\n",
    "     y_prediction = weight*x_data+bias\n",
    "##compute the loss\n",
    "with tf.name_scope('loss'):\n",
    "     loss = tf.reduce_mean(tf.square(y_data-y_prediction))\n",
    "     tf.summary.scalar('loss',loss)\n",
    "##creat optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "#creat train ,minimize the loss \n",
    "with tf.name_scope('train'):\n",
    "     train = optimizer.minimize(loss)\n",
    "#creat init\n",
    "with tf.name_scope('init'): \n",
    "     init = tf.global_variables_initializer()\n",
    "##creat a Session \n",
    "sess = tf.Session()\n",
    "#merged\n",
    "merged = tf.summary.merge_all()\n",
    "##initialize\n",
    "writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "sess.run(init)\n",
    "## Loop\n",
    "for step  in  range(101):\n",
    "    sess.run(train)\n",
    "    rs=sess.run(merged)\n",
    "    writer.add_summary(rs, step)\n",
    "print('over')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：http://www.cnblogs.com/fydeblog/p/7429344.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
